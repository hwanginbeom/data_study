{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Credit card overdue2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUKGg1p3v6of"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTSBZRubh4GP"
      },
      "source": [
        "!pip install Bayesian-Optimization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fdm-LXuiLZT"
      },
      "source": [
        "from bayes_opt import BayesianOptimization\n",
        "from sklearn.model_selection import cross_val_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPVBb9GOv-0V"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/data/dacon/신용카드 사용자 연체 예측 AI')\n",
        "train=pd.read_csv('train.csv')\n",
        "test=pd.read_csv('test.csv')\n",
        "submit=pd.read_csv('sample_submission.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIA8U8hZoeWv"
      },
      "source": [
        "# 결측치 합\n",
        "train.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba739sLEosrB"
      },
      "source": [
        "# 결측치 퍼센트 \n",
        "missing_df = train.isnull().sum().reset_index()\n",
        "missing_df.columns = ['column', 'count']\n",
        "missing_df['ratio'] = missing_df['count'] / train.shape[0]\n",
        "missing_df.loc[missing_df['ratio'] != 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK65sySDn0LD"
      },
      "source": [
        "# 기본적인 데이터 \n",
        "train.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-u5SoYgwOVk"
      },
      "source": [
        "object_col = []\n",
        "int_col = []\n",
        "for col in train.columns:\n",
        "    if train[col].dtype == 'object':\n",
        "        object_col.append(col)\n",
        "    else:\n",
        "        int_col.append(col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TeRAVCywQpW"
      },
      "source": [
        "# 범주형\n",
        "object_col"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8ssf-biGAwT"
      },
      "source": [
        "# 연속형\n",
        "int_col"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-gsn6PUpkKH"
      },
      "source": [
        "# 종속변수 체크\n",
        "train['credit'].value_counts().plot(kind='bar') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Rby_iV7qMM4"
      },
      "source": [
        "# 범주형 변수 분포\n",
        "for col in object_col: \n",
        "    train[col].value_counts().plot(kind='bar') \n",
        "    plt.title(col) \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uXuPTUTrHx_"
      },
      "source": [
        "# 이산형 변수 분포\n",
        "for col in int_col:\n",
        "    sns.distplot(train.loc[train[col].notnull(), col])\n",
        "    plt.title(col)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKlevo7PrzXL"
      },
      "source": [
        "# 이산형 변수 EDA \n",
        "train.loc[:,int_col].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEY0Fa0xtAik"
      },
      "source": [
        "numerical_feature = list(set(train.columns) - set(object_col) - set(['credit']))\n",
        "numerical_feature = np.sort(numerical_feature)\n",
        "numerical_feature\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdLuHDMXs3a_"
      },
      "source": [
        "train.loc[:,int_col]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uweYacsssNt"
      },
      "source": [
        "# 이변수, 삼변수 탐색\n",
        "sns.pairplot(train[list(numerical_feature) + ['credit']], hue='credit', \n",
        "             x_vars=numerical_feature, y_vars=numerical_feature)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luTjODG5uFMQ"
      },
      "source": [
        "# 수치형, 명목형 변수 간의 관계 탐색\n",
        "unique_list = train['credit'].unique()\n",
        "for row in object_col:\n",
        "    for col in numerical_feature:\n",
        "        plt.figure(figsize=(12,6))\n",
        "        sns.boxplot(x=row, y=col, hue='credit', data=train.dropna())\n",
        "        plt.title(row + \" - {}\".format(col))\n",
        "        plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7fPuYC5GDNd"
      },
      "source": [
        "train.loc[:,int_col]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2yVGJ4qnypo"
      },
      "source": [
        "\n",
        "train = train.drop(['index'], axis=1)\n",
        "train.fillna('NAN', inplace=True) \n",
        "\n",
        "\n",
        "test = test.drop(['index'], axis=1)\n",
        "test.fillna('NAN', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxGQzYMGGyZX"
      },
      "source": [
        "# MinMaxScaler\n",
        "# from sklearn import preprocessing as pc\n",
        "\n",
        "# for i in int_col:\n",
        "#     if i == 'credit':\n",
        "#         continue\n",
        "#     train[[i]] =pc.MinMaxScaler((0,5)).fit_transform(train[[i]])\n",
        "# # titanic[['Fare']] = pc.MinMaxScaler((0,10)).fit_transform(titanic[['Fare']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soRs64S5wpkI"
      },
      "source": [
        "train.loc[:,object_col]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssi2lz9ol2Nx"
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anZsQ7wXwUgw"
      },
      "source": [
        "# OnehotEncoder 부분\n",
        "enc = OneHotEncoder()\n",
        "enc.fit(train.loc[:,object_col])\n",
        "\n",
        "\n",
        "train_onehot_df = pd.DataFrame(enc.transform(train.loc[:,object_col]).toarray(), \n",
        "             columns=enc.get_feature_names(object_col))\n",
        "train.drop(object_col, axis=1, inplace=True)\n",
        "train = pd.concat([train, train_onehot_df], axis=1)\n",
        "\n",
        "test_onehot_df = pd.DataFrame(enc.transform(test.loc[:,object_col]).toarray(), \n",
        "             columns=enc.get_feature_names(object_col))\n",
        "test.drop(object_col, axis=1, inplace=True)\n",
        "test = pd.concat([test, test_onehot_df], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lzb8MhIawUj5"
      },
      "source": [
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "folds=[]\n",
        "for train_idx, valid_idx in skf.split(train, train['credit']):\n",
        "    folds.append((train_idx, valid_idx))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWp57_qHwUmf"
      },
      "source": [
        "# 데이터 분리는 StratifiedKFold 를 사용하여 y값 분포를 비슷하게 분리시킴. -> 5-fold\n",
        "# lightgbm의 default parameter로 훈련.\n",
        "# 30번 이상 개선 없을 경우 중단.\n",
        "# 각 5개의 fold를 훈련하여 저장\n",
        "\n",
        "random.seed(42)\n",
        "lgb_models={}\n",
        "for fold in range(5):\n",
        "    print(f'===================================={fold+1}============================================')\n",
        "    train_idx, valid_idx = folds[fold]\n",
        "    X_train, X_valid, y_train, y_valid = train.drop(['credit'],axis=1).iloc[train_idx].values, train.drop(['credit'],axis=1).iloc[valid_idx].values,\\\n",
        "                                         train['credit'][train_idx].values, train['credit'][valid_idx].values \n",
        "    lgb = LGBMClassifier(n_estimators=1000)\n",
        "    lgb.fit(X_train, y_train, \n",
        "            eval_set=[(X_train, y_train), (X_valid, y_valid)], \n",
        "            early_stopping_rounds=30,\n",
        "           verbose=100)\n",
        "    lgb_models[fold]=lgb\n",
        "    print(f'================================================================================\\n\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kf6yQUp-A1vk"
      },
      "source": [
        "    lgb.fit(X_train, y_train, \n",
        "            eval_set=[(X_train, y_train), (X_valid, y_valid)], \n",
        "            early_stopping_rounds=30,\n",
        "           verbose=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAhuPc4f1d-L"
      },
      "source": [
        "    lgb.fit(X_train, y_train, \n",
        "            eval_set=[(X_train, y_train), (X_valid, y_valid)], \n",
        "            early_stopping_rounds=30,\n",
        "           verbose=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKJC1xfriAwr"
      },
      "source": [
        "def bayesOpt(train_x, train_y):\n",
        "    lgbBO = BayesianOptimization(lgb_evaluate, {  'numLeaves':  (5, 90),  'maxDepth': (2, 90),   'scaleWeight': (1, 10000),  'minChildWeight': (0.01, 70), 'subsample': (0.4, 1), 'colSam': (0.4, 1) })\n",
        "    lgbBO.maximize(init_points=5, n_iter=30)\n",
        "    print(lgbBO.res)\n",
        "    return lgbBO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANDEXkpfiUwh"
      },
      "source": [
        "def lgb_evaluate(numLeaves, maxDepth, scaleWeight, minChildWeight, subsample, colSam, output = 'score'):\n",
        "    reg=LGBMClassifier(num_leaves=31, max_depth= 2,scale_pos_weight= scaleWeight, min_child_weight= minChildWeight, subsample= 0.4, colsample_bytree= 0.4, learning_rate=0.05,   n_estimators=20)\n",
        "    scores = cross_val_score(reg, X_train, y_train, cv=5, scoring='roc_auc')\n",
        "    # scores = cross_val_score(reg, train_x, train_y, cv=5, scoring='neg_mean_squared_error')\n",
        " \n",
        "    if output == 'score' :\n",
        "      return np.mean(scores)\n",
        "    if output == 'model' :\n",
        "      return reg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2IxZDgSrLzj"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifc9laoNiF9s"
      },
      "source": [
        "lgbBO = bayesOpt(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vBT3_TjwUpc"
      },
      "source": [
        "submit.iloc[:,1:]=0\n",
        "for fold in range(5):\n",
        "    submit.iloc[:,1:] += lgb_models[fold].predict_proba(test)/5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flqnqdsZzLSH"
      },
      "source": [
        "submit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YMchWGBwUqb"
      },
      "source": [
        "submit.to_csv('baseline_submission2.csv', index=False) # 0.7272812144\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1i_lLfcmmR1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}