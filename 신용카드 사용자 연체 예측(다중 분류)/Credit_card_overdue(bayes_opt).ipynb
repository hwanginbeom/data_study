{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Credit card overdue3.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUKGg1p3v6of"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTSBZRubh4GP"
      },
      "source": [
        "!pip install Bayesian-Optimization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fdm-LXuiLZT"
      },
      "source": [
        "from bayes_opt import BayesianOptimization\n",
        "from sklearn.model_selection import cross_val_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPVBb9GOv-0V"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/data/dacon/신용카드 사용자 연체 예측 AI')\n",
        "train=pd.read_csv('train.csv')\n",
        "test=pd.read_csv('test.csv')\n",
        "submit=pd.read_csv('sample_submission.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIA8U8hZoeWv"
      },
      "source": [
        "# 결측치 합\n",
        "train.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba739sLEosrB"
      },
      "source": [
        "# 결측치 퍼센트 \n",
        "missing_df = train.isnull().sum().reset_index()\n",
        "missing_df.columns = ['column', 'count']\n",
        "missing_df['ratio'] = missing_df['count'] / train.shape[0]\n",
        "missing_df.loc[missing_df['ratio'] != 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK65sySDn0LD"
      },
      "source": [
        "# 기본적인 데이터 \n",
        "train.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-u5SoYgwOVk"
      },
      "source": [
        "object_col = []\n",
        "int_col = []\n",
        "for col in train.columns:\n",
        "    if train[col].dtype == 'object':\n",
        "        object_col.append(col)\n",
        "    else:\n",
        "        int_col.append(col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TeRAVCywQpW"
      },
      "source": [
        "# 범주형\n",
        "object_col"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8ssf-biGAwT"
      },
      "source": [
        "# 연속형\n",
        "int_col"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-gsn6PUpkKH"
      },
      "source": [
        "# 종속변수 체크\n",
        "train['credit'].value_counts().plot(kind='bar') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Rby_iV7qMM4"
      },
      "source": [
        "# 범주형 변수 분포\n",
        "for col in object_col: \n",
        "    train[col].value_counts().plot(kind='bar') \n",
        "    plt.title(col) \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uXuPTUTrHx_"
      },
      "source": [
        "# 이산형 변수 분포\n",
        "for col in int_col:\n",
        "    sns.distplot(train.loc[train[col].notnull(), col])\n",
        "    plt.title(col)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKlevo7PrzXL"
      },
      "source": [
        "# 이산형 변수 EDA \n",
        "train.loc[:,int_col].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEY0Fa0xtAik"
      },
      "source": [
        "numerical_feature = list(set(train.columns) - set(object_col) - set(['credit']))\n",
        "numerical_feature = np.sort(numerical_feature)\n",
        "numerical_feature\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdLuHDMXs3a_"
      },
      "source": [
        "train.loc[:,int_col]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uweYacsssNt"
      },
      "source": [
        "# # 이변수, 삼변수 탐색\n",
        "# sns.pairplot(train[list(numerical_feature) + ['credit']], hue='credit', \n",
        "#              x_vars=numerical_feature, y_vars=numerical_feature)\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luTjODG5uFMQ"
      },
      "source": [
        "# # 수치형, 명목형 변수 간의 관계 탐색\n",
        "# unique_list = train['credit'].unique()\n",
        "# for row in object_col:\n",
        "#     for col in numerical_feature:\n",
        "#         plt.figure(figsize=(12,6))\n",
        "#         sns.boxplot(x=row, y=col, hue='credit', data=train.dropna())\n",
        "#         plt.title(row + \" - {}\".format(col))\n",
        "#         plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7fPuYC5GDNd"
      },
      "source": [
        "train.loc[:,int_col]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2yVGJ4qnypo"
      },
      "source": [
        "\n",
        "train = train.drop(['index'], axis=1)\n",
        "train.fillna('NAN', inplace=True) \n",
        "\n",
        "\n",
        "test = test.drop(['index'], axis=1)\n",
        "test.fillna('NAN', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxGQzYMGGyZX"
      },
      "source": [
        "# MinMaxScaler\n",
        "# from sklearn import preprocessing as pc\n",
        "\n",
        "# for i in int_col:\n",
        "#     if i == 'credit':\n",
        "#         continue\n",
        "#     train[[i]] =pc.MinMaxScaler((0,5)).fit_transform(train[[i]])\n",
        "# # titanic[['Fare']] = pc.MinMaxScaler((0,10)).fit_transform(titanic[['Fare']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soRs64S5wpkI"
      },
      "source": [
        "train.loc[:,object_col]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssi2lz9ol2Nx"
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anZsQ7wXwUgw"
      },
      "source": [
        "# OnehotEncoder 부분\n",
        "enc = OneHotEncoder()\n",
        "enc.fit(train.loc[:,object_col])\n",
        "\n",
        "\n",
        "train_onehot_df = pd.DataFrame(enc.transform(train.loc[:,object_col]).toarray(), \n",
        "             columns=enc.get_feature_names(object_col))\n",
        "train.drop(object_col, axis=1, inplace=True)\n",
        "train = pd.concat([train, train_onehot_df], axis=1)\n",
        "\n",
        "test_onehot_df = pd.DataFrame(enc.transform(test.loc[:,object_col]).toarray(), \n",
        "             columns=enc.get_feature_names(object_col))\n",
        "test.drop(object_col, axis=1, inplace=True)\n",
        "test = pd.concat([test, test_onehot_df], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lzb8MhIawUj5"
      },
      "source": [
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "folds=[]\n",
        "for train_idx, valid_idx in skf.split(train, train['credit']):\n",
        "    folds.append((train_idx, valid_idx))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWp57_qHwUmf"
      },
      "source": [
        "# 데이터 분리는 StratifiedKFold 를 사용하여 y값 분포를 비슷하게 분리시킴. -> 5-fold\n",
        "# lightgbm의 default parameter로 훈련.\n",
        "# 30번 이상 개선 없을 경우 중단.\n",
        "# 각 5개의 fold를 훈련하여 저장\n",
        "\n",
        "random.seed(42)\n",
        "lgb_models={}\n",
        "for fold in range(5):\n",
        "    print(f'===================================={fold+1}============================================')\n",
        "    train_idx, valid_idx = folds[fold]\n",
        "    X_train, X_valid, y_train, y_valid = train.drop(['credit'],axis=1).iloc[train_idx].values, train.drop(['credit'],axis=1).iloc[valid_idx].values,\\\n",
        "                                         train['credit'][train_idx].values, train['credit'][valid_idx].values \n",
        "    lgb = LGBMClassifier(n_estimators=1000)\n",
        "    lgb.fit(X_train, y_train, \n",
        "            eval_set=[(X_train, y_train), (X_valid, y_valid)], \n",
        "            early_stopping_rounds=30,\n",
        "           verbose=100)\n",
        "    lgb_models[fold]=lgb\n",
        "    print(f'================================================================================\\n\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRwb_bppYB9W"
      },
      "source": [
        "# 데이터 분리는 StratifiedKFold 를 사용하여 y값 분포를 비슷하게 분리시킴. -> 5-fold\n",
        "# lightgbm의 default parameter로 훈련.\n",
        "# 30번 이상 개선 없을 경우 중단.\n",
        "# 각 5개의 fold를 훈련하여 저장\n",
        "\n",
        "random.seed(42)\n",
        "xgb_models={}\n",
        "for fold in range(5):\n",
        "    print(f'===================================={fold+1}============================================')\n",
        "    train_idx, valid_idx = folds[fold]\n",
        "    X_train, X_valid, y_train, y_valid = train.drop(['credit'],axis=1).iloc[train_idx].values, train.drop(['credit'],axis=1).iloc[valid_idx].values,\\\n",
        "                                         train['credit'][train_idx].values, train['credit'][valid_idx].values \n",
        "    xgb = XGBClassifier(n_estimators=100)\n",
        "    xgb.fit(X_train, y_train, \n",
        "            eval_set=[(X_train, y_train), (X_valid, y_valid)], \n",
        "            # early_stopping_rounds=30,\n",
        "           verbose=100\n",
        "            )\n",
        "    xgb_models[fold]=xgb\n",
        "    print(f'================================================================================\\n\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeZUdoBabw7K"
      },
      "source": [
        "# 데이터 분리는 StratifiedKFold 를 사용하여 y값 분포를 비슷하게 분리시킴. -> 5-fold\n",
        "# lightgbm의 default parameter로 훈련.\n",
        "# 30번 이상 개선 없을 경우 중단.\n",
        "# 각 5개의 fold를 훈련하여 저장\n",
        "\n",
        "random.seed(42)\n",
        "xgb_models={}\n",
        "for fold in range(5):\n",
        "    print(f'===================================={fold+1}============================================')\n",
        "    train_idx, valid_idx = folds[fold]\n",
        "    X_train, X_valid, y_train, y_valid = train.drop(['credit'],axis=1).iloc[train_idx].values, train.drop(['credit'],axis=1).iloc[valid_idx].values,\\\n",
        "                                         train['credit'][train_idx].values, train['credit'][valid_idx].values \n",
        "    xgb = XGBClassifier(n_estimators=100)\n",
        "    xgb.fit(X_train, y_train, \n",
        "            eval_set=[(X_train, y_train), (X_valid, y_valid)], \n",
        "            # early_stopping_rounds=30,\n",
        "           verbose=100\n",
        "            )\n",
        "    xgb_models[fold]=xgb\n",
        "    print(f'================================================================================\\n\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol1kjfLZcqkj"
      },
      "source": [
        "  from sklearn.metrics import r2_score, mean_squared_error\n",
        "  import xgboost as xgb\n",
        "\n",
        "  # MAPE Metric\n",
        "  def mean_absolute_percentage_error(y_test, y_pred):\n",
        "      y_test, y_pred = np.array(y_test), np.array(y_pred)\n",
        "      return np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "\n",
        "  # 탐색 대상 함수 (XGBRegressor)\n",
        "  def XGB_cv(max_depth,learning_rate, n_estimators, gamma\n",
        "             ,min_child_weight, subsample\n",
        "             ,colsample_bytree, silent=True, nthread=-1):\n",
        "\n",
        "      # 모델 정의\n",
        "      model = xgb.XGBRegressor(max_depth=int(max_depth),\n",
        "                                learning_rate=learning_rate,\n",
        "                                n_estimators=int(n_estimators),\n",
        "                                gamma=gamma,\n",
        "                                min_child_weight=min_child_weight,\n",
        "                                subsample=subsample,\n",
        "                                colsample_bytree=colsample_bytree, \n",
        "                                nthread=nthread\n",
        "                                )\n",
        "      # 모델 훈련\n",
        "      model.fit(X_train, y_train)\n",
        "\n",
        "      # 예측값 출력\n",
        "      y_pred= model.predict(X_valid)\n",
        "\n",
        "      # 각종 metric 계산\n",
        "      rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
        "      r2 = r2_score(y_valid, y_pred)\n",
        "      mape = mean_absolute_percentage_error(y_valid, y_pred)\n",
        "\n",
        "      # 오차 최적화로 사용할 metric 반환\n",
        "      return r2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmnE1Lz2cwB9"
      },
      "source": [
        "  #  bayesian-optimization 라이브러리의 BayesianOptimization 클래스 import\n",
        "  from bayes_opt import BayesianOptimization\n",
        "  import numpy as np\n",
        "\n",
        "  # 실험해보고자하는 hyperparameter 집합\n",
        "  pbounds = {'max_depth': (3, 7),\n",
        "                'learning_rate': (0.01, 0.2),\n",
        "                'n_estimators': (5000, 10000),\n",
        "                'gamma': (0, 100),\n",
        "                'min_child_weight': (0, 3),\n",
        "                'subsample': (0.5, 1),\n",
        "                'colsample_bytree' :(0.2, 1)\n",
        "                }\n",
        "\n",
        "  # Bayesian optimization 객체 생성\n",
        "  # f : 탐색 대상 함수, pbounds : hyperparameter 집합\n",
        "  # verbose = 2 항상 출력, verbose = 1 최댓값일 때 출력, verbose = 0 출력 안함\n",
        "  # random_state : Bayesian Optimization 상의 랜덤성이 존재하는 부분을 통제 \n",
        "  bo=BayesianOptimization(f=XGB_cv, pbounds=pbounds, verbose=2, random_state=1 )    \n",
        "\n",
        "  # 메소드를 이용해 최대화 과정 수행\n",
        "  # init_points :  초기 Random Search 갯수\n",
        "  # n_iter : 반복 횟수 (몇개의 입력값-함숫값 점들을 확인할지! 많을 수록 정확한 값을 얻을 수 있다.)\n",
        "  # acq : Acquisition Function들 중 Expected Improvement(EI) 를 사용\n",
        "  # xi : exploration 강도 (기본값은 0.0)\n",
        "  bo.maximize(init_points=2, n_iter=10, acq='ei', xi=0.01)\n",
        "\n",
        "  # ‘iter’는 반복 회차, ‘target’은 목적 함수의 값, 나머지는 입력값을 나타냅니다. \n",
        "  # 현재 회차 이전까지 조사된 함숫값들과 비교하여, 현재 회차에 최댓값이 얻어진 경우, \n",
        "  # bayesian-optimization 라이브러리는 이를 자동으로 다른 색 글자로 표시하는 것을 확인할 수 있습니다\n",
        "\n",
        "  # 찾은 파라미터 값 확인\n",
        "  print(bo.max)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiWV2hmqrWJj"
      },
      "source": [
        "print(bo.max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWnd_wEOt387"
      },
      "source": [
        "bo.max['params']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FJbll4Ms6QR"
      },
      "source": [
        "# for i in bo.max['params'].keys()\n",
        "for key, val in bo.max['params'].items():\n",
        "    print(key)\n",
        "    print(type(val))\n",
        "# bo.max.items()[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeFJSaxkuzCF"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "grid_dtree = GridSearchCV(XGBClassifier(), param_grid=bo.max['params'], cv=3, refit=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw76UZyEuii1"
      },
      "source": [
        "grid_cv = GridSearchCV(dt, param_grid=bo.max['params'], scoring='accuracy', cv=skfold)\n",
        "best_df_clf = grid_cv.best_estimator_\n",
        "pred1 = best_df_clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTy1PRxvri7A"
      },
      "source": [
        "# 데이터 분리는 StratifiedKFold 를 사용하여 y값 분포를 비슷하게 분리시킴. -> 5-fold\n",
        "# lightgbm의 default parameter로 훈련.\n",
        "# 30번 이상 개선 없을 경우 중단.\n",
        "# 각 5개의 fold를 훈련하여 저장\n",
        "\n",
        "random.seed(42)\n",
        "xgb_models={}\n",
        "for fold in range(5):\n",
        "    print(f'===================================={fold+1}============================================')\n",
        "    train_idx, valid_idx = folds[fold]\n",
        "    X_train, X_valid, y_train, y_valid = train.drop(['credit'],axis=1).iloc[train_idx].values, train.drop(['credit'],axis=1).iloc[valid_idx].values,\\\n",
        "                                         train['credit'][train_idx].values, train['credit'][valid_idx].values \n",
        "    xgb = XGBClassifier(\n",
        "                        # n_estimators=100,\n",
        "                        colsample_bytree=0.2,\n",
        "                        gamma= 0.0,\n",
        "                        learning_rate= 0.01,\n",
        "                        max_depth= 7,\n",
        "                        min_child_weight = 3.0,\n",
        "                        n_estimators= 7499,\n",
        "                        subsample= 0.5)\n",
        "    xgb.fit(X_train, y_train, \n",
        "            eval_set=[(X_train, y_train), (X_valid, y_valid)], \n",
        "            # early_stopping_rounds=30,\n",
        "           verbose=100\n",
        "            )\n",
        "    xgb_models[fold]=xgb\n",
        "    print(f'================================================================================\\n\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kf6yQUp-A1vk"
      },
      "source": [
        "    lgb.fit(X_train, y_train, \n",
        "            eval_set=[(X_train, y_train), (X_valid, y_valid)], \n",
        "            early_stopping_rounds=30,\n",
        "           verbose=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Wm7xvkArVqV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAhuPc4f1d-L"
      },
      "source": [
        "    # lgb.fit(X_train, y_train, \n",
        "    #         eval_set=[(X_train, y_train), (X_valid, y_valid)], \n",
        "    #         early_stopping_rounds=30,\n",
        "    #        verbose=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKJC1xfriAwr"
      },
      "source": [
        "def bayesOpt(train_x, train_y):\n",
        "    lgbBO = BayesianOptimization(lgb_evaluate, {  'numLeaves':  (5, 90),  'maxDepth': (2, 90),   'scaleWeight': (1, 10000),  'minChildWeight': (0.01, 70), 'subsample': (0.4, 1), 'colSam': (0.4, 1) })\n",
        "    lgbBO.maximize(init_points=5, n_iter=30)\n",
        "    print(lgbBO.res)\n",
        "    return lgbBO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANDEXkpfiUwh"
      },
      "source": [
        "def lgb_evaluate(numLeaves, maxDepth, scaleWeight, minChildWeight, subsample, colSam, output = 'score'):\n",
        "    reg=LGBMClassifier(num_leaves=31, max_depth= 2,scale_pos_weight= scaleWeight, min_child_weight= minChildWeight, subsample= 0.4, colsample_bytree= 0.4, learning_rate=0.05,   n_estimators=20)\n",
        "    scores = cross_val_score(reg, X_train, y_train, cv=5, scoring='roc_auc')\n",
        "    # scores = cross_val_score(reg, train_x, train_y, cv=5, scoring='neg_mean_squared_error')\n",
        " \n",
        "    if output == 'score' :\n",
        "      return np.mean(scores)\n",
        "    if output == 'model' :\n",
        "      return reg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2IxZDgSrLzj"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifc9laoNiF9s"
      },
      "source": [
        "lgbBO = bayesOpt(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vBT3_TjwUpc"
      },
      "source": [
        "submit.iloc[:,1:]=0\n",
        "for fold in range(5):\n",
        "    submit.iloc[:,1:] += lgb_models[fold].predict_proba(test)/5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcfM1B53Zl6z"
      },
      "source": [
        "submit.iloc[:,1:]=0\n",
        "for fold in range(5):\n",
        "    submit.iloc[:,1:] += xgb_models[fold].predict_proba(test)/5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flqnqdsZzLSH"
      },
      "source": [
        "submit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YMchWGBwUqb"
      },
      "source": [
        "submit.to_csv('baseline_submission2.csv', index=False) # 0.7272812144\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1i_lLfcmmR1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}